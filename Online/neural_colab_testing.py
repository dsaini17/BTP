# -*- coding: utf-8 -*-
"""Neural_colab_testing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Kn9U_5zlv0FQCq32GDtkN7XZOpKpIc2D

# Kaggle API
"""

!pip install kaggle
from google.colab import files
uploaded = files.upload()

"""# Downloading Dataset"""

import os
! mkdir .kaggle
! mv kaggle.json .kaggle/
! kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge --force
! cp ".kaggle/competitions/challenges-in-representation-learning-facial-expression-recognition-challenge/fer2013.tar.gz" .
! tar -xzf fer2013.tar.gz
os.listdir()

"""# Data Preprocessing"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

dataset = pd.read_csv('fer2013/fer2013.csv')
dataset

y = dataset.iloc[:,0:1].values

X = np.zeros(shape=(dataset.shape[0],48,48))

for i in range(dataset.shape[0]):
    a = dataset['pixels'][i].split(' ')
    b = [int(x) for x in a]
    c = np.asarray(b,dtype = 'float32')
    d = c.reshape(48,48)
    X[i] = d
    
X = X.astype('float32')
X = X/255

classes = 7

index1 = 28709 # Cross-Validation SET ( Public Test )
index2 = 32298 # Final Test SET ( Private Test )

X_train = X[0:index1,:]
X_validate = X[index1:index2,:]
X_test = X[index2:,:]
y_train = y[0:index1,:]
y_validate = y[index1:index2,:]
y_test = y[index2:,:]

print(X_train.shape)
print(y_train.shape)

X

"""# Neural Network"""

import keras
from keras.models import Sequential
from keras.layers import Dense,Dropout,Flatten,Activation,Convolution2D,MaxPooling2D,BatchNormalization
from keras.utils import np_utils

# Data Reshaping
y_train = np_utils.to_categorical(y_train,classes)
y_validate = np_utils.to_categorical(y_validate,classes)
y_test = np_utils.to_categorical(y_test,classes)
X_train = X_train.reshape(X_train.shape[0],48,48,1)
X_validate = X_validate.reshape(X_validate.shape[0],48,48,1)
X_test = X_test.reshape(X_test.shape[0],48,48,1)

print(X_train.shape)
print(y_train.shape)
print(X_validate.shape)
print(y_validate.shape)
print(X_test.shape)
print(y_test.shape)

model = Sequential()

model.summary()

# =============================================================================
# Section 1
# =============================================================================
model.add(Convolution2D(128,(4,4),input_shape=(48,48,1),strides = 2))


# =============================================================================
# Section 2
# =============================================================================
model.add(Convolution2D(128,(4,4),strides = 2))

# =============================================================================
# Section 3
# =============================================================================
model.add(Convolution2D(128,(4,4),strides = 2))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())

model.summary()

# =============================================================================
# Section 8
# =============================================================================
model.add(Dense(512))
model.add(Activation('relu'))

# =============================================================================
# Section 9
# =============================================================================
model.add(Dense(128))
model.add(Activation('relu'))

# =============================================================================
# Section 10
# =============================================================================
model.add(Dense(classes, activation='softmax'))

model.summary()

class LossHistory(keras.callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.train_losses = []
        self.val_losses = []

    def on_epoch_end(self, batch, logs={}):
        self.train_losses.append(logs.get('loss'))
        self.val_losses.append(logs.get('val_loss'))

class AccHistory(keras.callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.train_acc = []
        self.val_acc = []

    def on_epoch_end(self, batch, logs={}):
        self.train_acc.append(logs.get('acc'))
        self.val_acc.append(logs.get('val_acc'))

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

history1 = LossHistory()
history2 = AccHistory()

from keras.callbacks import ModelCheckpoint
filepath1="weights.best.acc.hdf5"
filepath2="weights.best.loss.hdf5"
checkpoint1 = ModelCheckpoint(filepath1, monitor='val_acc', verbose=1, save_best_only=True, mode='max')
checkpoint2 = ModelCheckpoint(filepath2, monitor='val_loss', verbose=1, save_best_only=True, mode='min')

callbacks_list = [checkpoint1,checkpoint2,history1,history2]

model.fit(X_train, y_train, 
          batch_size=128, epochs=10, verbose=1, validation_data = (X_validate,y_validate),callbacks=callbacks_list)

test_score = model.evaluate(X_test, y_test, verbose=1)

plt.plot(history1.train_losses,color = 'blue')
plt.plot(history1.val_losses,color = 'red')
#plt.plot(history.history['val_acc'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('time')
plt.legend(['train', 'validation'], loc='lower right')
plt.show()

print(history1.train_losses)
print(history1.val_losses)

print(history2.train_acc)
print(history2.val_acc)

plt.plot(history2.train_acc,color = 'blue')
plt.plot(history2.val_acc,color = 'red')
#plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('time')
plt.legend(['train', 'validation'], loc='lower right')
plt.show()

print(X_validate.shape)
print(y_validate.shape)

validation_score = model.evaluate(X_validate, y_validate, verbose=1)

print(' Validation SET Accuracy = '+ str(validation_score[1]))
print(' Test SET Accuracy = '+ str(test_score[1]))

"""# Visualization"""

config = model.get_config()
print(config)

# https://pypi.python.org/pypi/pydot
!apt-get -qq install -y graphviz && pip install -q pydot
import pydot

file = 'weights.hdf5'
model.save_weights(file)

os.listdir()

from google.colab import files
files.download('weights.hdf5')

import pydot
from IPython.display import SVG
from keras.utils.vis_utils import model_to_dot

SVG(model_to_dot(model).create(prog='dot', format='svg'))

score = model.evaluate(X_train,y_train,verbose = 1)
score

"""# Metrics"""

from sklearn.metrics import confusion_matrix,precision_score,recall_score,f1_score,cohen_kappa_score

y_pred = model.predict(X_test)
print(y_test.shape)
print(y_pred.shape)

test_data = y_validate.argmax(1)
pred_data = y_pred.argmax(1)

test_data = y_validate.argmax(1)
pred_data = y_pred.argmax(1)
cm = confusion_matrix(test_data,pred_data)
print(cm)

val = 0
for i in range(0,7):
    val += cm[i][i]
print('Validation Set Accuracy = ' + str(val/(index2-index1)))

max_val = cm.max()

plt.imshow(cm)
plt.imshow(cm,cmap='gray')

weight_list = []

for i in range(0,7):
    weight_list.append(0)

for x in pred_data:
    weight_list[x] += 1
    
nm = cm


for i in range(0,7):
    for j in range(0,7):
        nm[i][j] *= max_val
        nm[i][j] /= weight_list[i]
        
plt.imshow(cm,cmap = 'gray')        
plt.imshow(cm,interpolation='nearest') # Visualizing Confusion Matrix

# Heat Map

labels = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']

import seaborn as sn

df_cm = pd.DataFrame(nm,index = [labels[i] for i in range(0,7)],columns = [labels[i] for i in range(0,7)])
sn.set(font_scale = 1)
sn.heatmap(df_cm,annot = True)



"""# Web Cam

Run time dies automatically on Execution
"""

import cv2

cv2.namedWindow('image', cv2.WINDOW_NORMAL)
cv2.imshow('image',img)

cv2.waitKey(0)
cv2.destroyAllWindows()

cam = cv2.VideoCapture(0)

while True:
    ret, frame = cam.read()
    cv2.imshow('video out',img)
    k = cv2.waitKey(10)& 0xff

    if k%256 == 27:
        # ESC pressed
        print("Escape hit, closing...")
        break

# =============================================================================
#     elif k%256 == 32:
#         # SPACE pressed
#         img_name = "opencv_frame_{}.png".format(img_counter)
#         cv2.imwrite(img_name, frame)
#         print("{} written!".format(img_name))
#         img_counter += 1
# 
# =============================================================================
cam.release()

cv2.destroyAllWindows()